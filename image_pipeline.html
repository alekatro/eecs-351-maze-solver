<!DOCTYPE html>
<!-- Template by Quackit.com -->
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->

    <title>EECS 351 Project - Image Pipeline</title>

    <!-- Bootstrap Core CSS -->
    <link href="css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom CSS: You can use this stylesheet to override any Bootstrap styles and/or apply your own styles -->
    <link href="css/custom.css" rel="stylesheet">

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

</head>

<body>

    <!--------------------------------------------------------------- Navigation Bar ---------------------------------------------------------------->
    <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
        <div class="container">
            <!-- Logo and responsive toggle -->
            <div class="navbar-header">
                <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
            </div>
            <!-- Navbar links -->
            <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
                <ul class="nav navbar-nav">
                    <li class>
                        <a class="navbar-brand" href="index.html">
                            <span class="glyphicon glyphicon-signal"></span> 
                        EECS 351
                        </a>
                    </li>
                    <li class="active">
                        <a href="image_pipeline.html">Image Pipeline</a>
                    </li>
                    <li class>
                        <a href="bfs_algorithm.html">BFS Algorithm</a>
                    </li>
                    <li class>
                        <a href="watershed.html">Watershed Algorithm</a>
                    </li>
                    <li class>
                        <a href="a_star.html">A* Search Algorithm</a>
                    </li>
                    <li class>
                        <a href="contact.html">Contact</a>
                    </li>
                </ul>
                <ul class="nav navbar-nav navbar-right">
                    <li class>
                        <a href="progress_report.html">Progress Report</a>
                    </li>

                </ul>
            </div>
            <!-- /.navbar-collapse -->
        </div>
        <!-- /.container -->
    </nav>
    <!---------------------------------------------------------------------------------------------------------------------------------------------->
    
    <!--------------------------------------------------------------- Title Heading ---------------------------------------------------------------->
    <div class="container">
        <div class="row">
            <div class="col-lg-12">
                <h1 class="page-header">Image Pipeline</h1>
            </div>
        </div>
    </div>
    <!---------------------------------------------------------------------------------------------------------------------------------------------->
    
    <!------------------------------------------------------------------ Text Section ------------------------------------------------------------------->
    <div class="container">
        <div class="row">
            <div class ="col-md-6">
                <h3>Part 1: Image Preparation</h3>
            </div>
            <div class="col-lg-12">
                <p> To solve our mazes, we must first create a representation from the original maze image. We do this by loading an image into MATLAB, and performing a thresholding filter operation. This is applied since many mazes are not saved as lossless PNG photos with clear delineations between the black walls and the white passageways. This allows us to perform later operations on a cleaned image which results in better output later on. We found that a good heuristic for the threshold cutoff is approximately a pixel value of 90, which sets all pixels lower than that to 0, and all greater or equal to that to 255, the maximum value.
                <br><br>
                Next, we noticed that the maze had a lot of additional whitespace outside of the outermost walls which made no contribution to the actual solution of the maze, and would make processing it more computationally costly, so we explored ways to remove the border. Our first approach was edge detection using a Canny filter which was implemented in MATLAB, and it yielded an image that can be seen below. The left image is the input, while the right contains the detected edges.
                <br>
                <br>
                
                <div class="col-md-6">
                    <img class="img-responsive center-block" src="pictures/maze3.jpg" alt="Original Maze">
                </div>
                <div class="col-md-6">
                    <img class="img-responsive center-block" src="pictures/Edges3.png" alt="Compressed Maze">
                </div>
                
                <br>
                <br>
                We found that this effectively discovered borders, however when cropping the image based on these edge-detection outputs, we found inconsistencies, where sometimes a border could get cut off if it was too small, or a white border of pixels would be left in the image. Instead of performing this edge detection, we decided to pursue a simpler route of using the maze's matrix representation to our advantage. By thresholding the image, we were performing a sort of edge detection, and there was a line at which the whitespace stopped and the maze began, so we simply detected this on all four sides and cropped the image accordingly. This resulted in the following cropped maze.
                <br>
                <br>
                
                <div class="row centered">
                    <div class="col-md-3">
                    </div>
                    <div class="col-md-6">
                        <img class="img-responsive center-block" src="pictures/autoCropped_maze3.png" alt="">
                    </div>
                    <div class="col-md-3">
                    </div>
                </div>
                </p>
            </div>
            <div class ="col-md-6">
                <br>
                <br>
                <br>
                <h3>Part 2: Image Compression</h3>
            </div>
            <div class="col-lg-12">
                <p> As one may notice, the image is large enough for one to comfortably see, which means that many of the borders and whitespaces span multiple pixels. When employing graph search algorithms on this maze, this would lead to many adjacent nodes which do not add any meaningful information to the solution path, and would simply increase the computational complexity of solving the shortest path. One approach at simplifying this was performing a Hough transform on the image, which detects lines, and selecting the 'n' most significant peaks in the transform, which represents the 'n' most significant lines in the image. Unfortunately, this leads to results that are seen below, where some lines are detected, others are not detected, and there are a number of duplicate lines which are slightly skewed due to the width of the border walls. Detected lines are marked with green lines with Xs at their endpoints.
                </p>
                <br>

                <div class="row centered">
                    <div class="col-md-3">
                    </div>
                    <div class="col-md-6">
                        <img class="img-responsive center-block" src="pictures/HoughTransform.png" alt="" height="300" width="300">
                            </div>
                    <div class="col-md-3">
                    </div>
                </div>
                
                <br>
                <p>
                Alternatively, we though of using convolution to 'expand' the borders and thereby thin out the white passageways. This worked reasonably well, and could be perormed with a kernel that was proportional to the size of the passageways in order to make sure that no information would be lost. An example of this output is shown below. However, this still left a relatively large number of non-necessary nodes to check in a search algorithm, so a better solution was still desired.
                </p>
                <br>
                
                <div class="row centered">
                    <div class="col-md-3">
                    </div>
                    <div class="col-md-6">
                        <img class="img-responsive center-block" src="pictures/thickMaze.png" alt="">
                            </div>
                    <div class="col-md-3">
                    </div>
                </div>
                
                <p>
                <br>
                Finally, we had the thought of exploiting the well-formatted nature of these mazes. We saw that the maze walls had a fixed width/height, and these squares were extended to form lines on the maze. Thus, we wanted to use a convolution in both directions with a vector, which would illustrate where the vertical and horizontal 'gridlines' of the image were, and showed how these gridlines occurred at a certain frequency which we could measure. This frequency corresponds to the characteristic square block used in the formation of the white space. The vertical and horizontal convolutions are seen superimposed and thresholded in the image below.
                </p>
                <br>

                <div class="row centered">
                    <div class="col-md-3">
                    </div>
                    <div class="col-md-6">
                        <img class="img-responsive center-block" src="pictures/gridlines.png" alt="">
                            </div>
                    <div class="col-md-3">
                    </div>
                </div>
                
                <br>
                <p>
                The gridlines contained the characteristic block of whitespace that was used in the maze, and the 'missing' lines are due to a lack of large wall in the area. After outputting this, we could calculate the mode of the width and height of each of these squares, and thus know the exact size of the characteristic whitespace. Then we could convolve the complement of the image with a kernel that was half the size of this whitespace in each dimension which would 'expand' the border to occupy the area where the whitespace resides. Then, we thresholded the resulting output such that if there was any non-zero response, it would be set to 255. By doing this, and knowning the width of the white space, we could sample the image of the maze to take pixels at a frequency of the width of this whitespace apart to obtain an image that was approximately the best possible compression. This resulted in the both the borders and the whitespace being either 1 or 2 pixels wide, depending on the exact sampling frequency and the specific pattern at that particular location in the maze. This was very successful at compressing the maze, and resulted in very small outputs across all the sample mazes we tried. In this case, the autocropped maze dimensions, without compression, was 310x310, and the compressed version is 59x59, which is approximately 4% of the original size. The compressed image is seen below, and is upsampled for visibility. The actual compression will vary from maze to maze, depending on how large the borders and whitespace are, respectively. However, this approach should be applicable to all well-formatted mazes, in which the wall and white space size are consistent and form a rectangular 'grid' of squares. Further work could be done to get this approximation into the perfectly compressed maze using a combination of this technique and algorithmic post-processing, or other techniques focused on reconstructing the maze entirely.
                </p>
                <br>
                
                <div class="row centered">
                    <div class="col-md-6">
                        <img class="img-responsive center-block" src="pictures/maxCompression.png" alt="">
                    </div>
                    <div class="col-md-6">
                        <img class="img-responsive center-block" src="pictures/maxCompression_upsampled.png" alt="" width="300">
                    </div>
                </div>
                
            </div>
            <div class ="col-md-6">
                <br>
                <br>
                <br>
                <h3>Part 3: Automatic Start/End Detection</h3>
            </div>
            <div class="col-lg-12">
                <p> Now with a minimal representation of the maze, we can automate our processing by detecting the start and stop of the maze. We can take advantage of the fact that the outside of the image will always be black borders, apart from the start and stop of the maze. Thus, we can simply search for the start and stop, which can be the starting point for our search algorithms to solve the maze.
                <br><br>
                </p>
            </div>
            <div class ="col-md-6">
             <br>
             <br>
             <br>
             <h3>DSP Tools Used in the Image Pipeline</h3>
             </div>
             
             <div class="col-lg-12">
             <p>
                In order to create our compressed maze, we heavily relied on the convolution operation, which is defined mathematically as the sum of a kernel times the part of the image it is covering. This operation allows us to see the similarity between the image and the kernel at each particular location, and was essential for us to use this in our implementation of our compression algorithm.
             <br>
             <br>
                Additionally, we used the idea of sampling, a fundamental operation in digital signal processing. This operation is used to obtain a finite amount of points from a signal, and great care is taken to ensure that there are enough samples taken in order to ensure the signal can be reconstructed. We used this operation when compressing our maze by manipulating the frequency of the white and black pixels in the maze, and sampling at a frequency that would keep a minimal representation of the maze in a matrix format.
             <br>
             <br>
                A DSP tool used in the development of the pipeline from outside of the class was the Hough Transform. This transform works by searching for lines in the original image, and using 'votes' to indicate if that line is truly present or not. Thus, a line which is supporte by many points will be a prominent feature in the feature space, and we can thus see how we can take the most significant lines in the feature space to detect lines in our maze image. In practice, despite testing multiple values for the parameters, we could not get consistent behavior between mazes and even had a hard time detecting all the lines in a single maze image. Given more time it would be interesting to study how we could use this to create an even greater compression of our maze image.
             </p>
             </div>
            <!--<div class ="col-md-6">
                <br>
                <br>
                <br>
                <h3>Summary</h3>
            </div>
            
            <div class="col-lg-12">
                <!--<div class="col-lg-12">-- >
                <p> We created an image pipeline that could take an input image, as seen on the left, and convert it into an output image, as seen on the right. However, for the sake of visibility in the discussion of the algorithms, we will be using the larger versions of the maze. The complexity of computations would be significantly be reduced using this approach, however.
                </p>
                <br>

                <div class="row centered">
                    <div class="col-md-6">
                        <img class="img-responsive center-block" src="pictures/maze3.jpg" alt="Original Maze">
                    </div>
                    <div class="col-md-6">
                        <img class="img-responsive center-block" src="pictures/maxCompression_upsampled.png" alt="Compressed Maze" width="300">
                    </div>
                </div>
            </div>-->
        </div>
    </div>
    <!-------------------------------------------------------------------------------------------------------------------------------------------------->
    
    
    
    
    
    <!------------------------------------------------------------------ Page Footer ------------------------------------------------------------------->
    
    <footer>
        <div class="copyright">
            <div class="container">
                <br>
                <br>
                <br>
                <br>
                <p>Copyright &copy;  |  Team 7, EECS 351  |  April 23, 2019</p>
            </div>
        </div>
    </footer>
    <!-------------------------------------------------------------------------------------------------------------------------------------------------->
    
    
    <!-- jQuery -->
    <script src="js/jquery-1.11.3.min.js"></script>
    
    <!-- Bootstrap Core JavaScript -->
    <script src="js/bootstrap.min.js"></script>
    
</body>

</html>
